{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Bidirectional Encoder Representations from Transformers for Multi-class classification","metadata":{"id":"Cfkx25DvdoCl"}},{"cell_type":"markdown","source":"1. Intuitively understand what BERT is\n2. Preprocess text data for BERT and build PyTorch Dataset (tokenization, attention masks, and padding)\n3. Use Transfer Learning to build Sentiment Classifier using the Transformers library by Hugging Face\n4. Evaluate the model on test data\n5. Predict sentiment on raw text\nLet's get started!","metadata":{"id":"c8ZDpNWXeKr4"}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"JcwuRPR347MW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /content/drive/My Drive/test\n","metadata":{"id":"pa3ntVGb7ow_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"id":"syG0hpBr7vFX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers","metadata":{"id":"dFkICxxQ7x9p","execution":{"iopub.status.busy":"2021-12-30T22:24:41.211465Z","iopub.execute_input":"2021-12-30T22:24:41.212413Z","iopub.status.idle":"2021-12-30T22:24:49.712716Z","shell.execute_reply.started":"2021-12-30T22:24:41.212293Z","shell.execute_reply":"2021-12-30T22:24:49.711872Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nimport torch\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\n\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 12, 8\n\nRANDOM_SEED = 42\n","metadata":{"id":"eZ8eUD7870G5","execution":{"iopub.status.busy":"2021-12-30T22:24:49.714392Z","iopub.execute_input":"2021-12-30T22:24:49.714667Z","iopub.status.idle":"2021-12-30T22:24:56.830443Z","shell.execute_reply.started":"2021-12-30T22:24:49.714636Z","shell.execute_reply":"2021-12-30T22:24:56.829768Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"np.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"LUJHWbbc79HH","execution":{"iopub.status.busy":"2021-12-30T22:24:56.831985Z","iopub.execute_input":"2021-12-30T22:24:56.832223Z","iopub.status.idle":"2021-12-30T22:24:56.887411Z","shell.execute_reply.started":"2021-12-30T22:24:56.832191Z","shell.execute_reply":"2021-12-30T22:24:56.886699Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":" torch.cuda.is_available()","metadata":{"id":"DxOZeRe6X04T","execution":{"iopub.status.busy":"2021-12-30T22:25:02.238942Z","iopub.execute_input":"2021-12-30T22:25:02.239462Z","iopub.status.idle":"2021-12-30T22:25:02.245131Z","shell.execute_reply.started":"2021-12-30T22:25:02.239424Z","shell.execute_reply":"2021-12-30T22:25:02.244369Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Data Exploration\n","metadata":{"id":"8xGv94SkfkxI"}},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/examtask/testing_data.csv\")\ndf = pd.read_csv(\"../input/examtask/training_data.csv\")\ndf['category'].value_counts()","metadata":{"id":"1OP1qSCp8Cva","execution":{"iopub.status.busy":"2021-12-30T22:28:43.745840Z","iopub.execute_input":"2021-12-30T22:28:43.746335Z","iopub.status.idle":"2021-12-30T22:28:43.797247Z","shell.execute_reply.started":"2021-12-30T22:28:43.746300Z","shell.execute_reply":"2021-12-30T22:28:43.796536Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_test.drop('category', axis=1, inplace=True)\n","metadata":{"id":"NU_ijaohxolm","execution":{"iopub.status.busy":"2021-12-30T22:28:46.814130Z","iopub.execute_input":"2021-12-30T22:28:46.814916Z","iopub.status.idle":"2021-12-30T22:28:46.821656Z","shell.execute_reply.started":"2021-12-30T22:28:46.814863Z","shell.execute_reply":"2021-12-30T22:28:46.820081Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"possible_labels = df.category.unique()\n","metadata":{"id":"-GiXuHFVK-mU","execution":{"iopub.status.busy":"2021-12-30T22:28:51.621875Z","iopub.execute_input":"2021-12-30T22:28:51.622349Z","iopub.status.idle":"2021-12-30T22:28:51.629710Z","shell.execute_reply.started":"2021-12-30T22:28:51.622295Z","shell.execute_reply":"2021-12-30T22:28:51.627924Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"possible_labels = df.category.unique()\n\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\nlabel_dict\ndf['label'] = df.category.replace(label_dict)\n","metadata":{"id":"7ZpbCWg58ex0","execution":{"iopub.status.busy":"2021-12-30T22:28:57.979102Z","iopub.execute_input":"2021-12-30T22:28:57.979349Z","iopub.status.idle":"2021-12-30T22:28:58.004172Z","shell.execute_reply.started":"2021-12-30T22:28:57.979319Z","shell.execute_reply":"2021-12-30T22:28:58.003551Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df = df[['title', 'label']]\n","metadata":{"id":"UMz67NaX9EV6","execution":{"iopub.status.busy":"2021-12-30T22:29:00.425256Z","iopub.execute_input":"2021-12-30T22:29:00.425504Z","iopub.status.idle":"2021-12-30T22:29:00.431502Z","shell.execute_reply.started":"2021-12-30T22:29:00.425475Z","shell.execute_reply":"2021-12-30T22:29:00.430596Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-12-30T22:29:02.610153Z","iopub.execute_input":"2021-12-30T22:29:02.610415Z","iopub.status.idle":"2021-12-30T22:29:02.622047Z","shell.execute_reply.started":"2021-12-30T22:29:02.610385Z","shell.execute_reply":"2021-12-30T22:29:02.621300Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"\n\n```\n# Here we can see our classes are highly imbalanced\n```\n\n","metadata":{"id":"LqzLIM_xfuaA"}},{"cell_type":"code","source":"sns.countplot(df.label)\nplt.xlabel('review score');\n","metadata":{"id":"qIV989gY8KTd","execution":{"iopub.status.busy":"2021-12-30T22:29:07.017437Z","iopub.execute_input":"2021-12-30T22:29:07.017701Z","iopub.status.idle":"2021-12-30T22:29:07.358036Z","shell.execute_reply.started":"2021-12-30T22:29:07.017672Z","shell.execute_reply":"2021-12-30T22:29:07.357399Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Data Preprocessing:- \n\nWe already know that Machine Learning models don't work with raw text. You need to convert text to numbers (of some sort). BERT requires even more attention (good one, right?). Here are the requirements:\n\n1. Add special tokens to separate sentences and do classification\n2. Pass sequences of constant length (introduce padding)\n3. Create array of 0s (pad token) and 1s (real token) called attention mask","metadata":{"id":"dVrco0MxgT_z"}},{"cell_type":"code","source":"PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n","metadata":{"id":"T-hS6x9U9TkL","execution":{"iopub.status.busy":"2021-12-30T22:29:11.068539Z","iopub.execute_input":"2021-12-30T22:29:11.069236Z","iopub.status.idle":"2021-12-30T22:29:11.072862Z","shell.execute_reply.started":"2021-12-30T22:29:11.069182Z","shell.execute_reply":"2021-12-30T22:29:11.072111Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","metadata":{"id":"jWTpv2F8AcB1","execution":{"iopub.status.busy":"2021-12-30T22:29:13.044256Z","iopub.execute_input":"2021-12-30T22:29:13.044797Z","iopub.status.idle":"2021-12-30T22:29:15.283229Z","shell.execute_reply.started":"2021-12-30T22:29:13.044754Z","shell.execute_reply":"2021-12-30T22:29:15.282058Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\ntokens = tokenizer.tokenize(sample_txt)\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\n\nprint(f' Sentence: {sample_txt}')\nprint(f'   Tokens: {tokens}')\nprint(f'Token IDs: {token_ids}')\n","metadata":{"id":"XXxU3FuuAetZ","execution":{"iopub.status.busy":"2021-12-30T22:29:18.946440Z","iopub.execute_input":"2021-12-30T22:29:18.946967Z","iopub.status.idle":"2021-12-30T22:29:18.955261Z","shell.execute_reply.started":"2021-12-30T22:29:18.946928Z","shell.execute_reply":"2021-12-30T22:29:18.954513Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Special Tokens\n","metadata":{"id":"ttlr20JkhHcA"}},{"cell_type":"code","source":"tokenizer.sep_token, tokenizer.sep_token_id\ntokenizer.cls_token, tokenizer.cls_token_id\ntokenizer.pad_token, tokenizer.pad_token_id\ntokenizer.unk_token, tokenizer.unk_token_id\n","metadata":{"id":"aJsqlw-2AnYc","execution":{"iopub.status.busy":"2021-12-30T22:29:21.340553Z","iopub.execute_input":"2021-12-30T22:29:21.341111Z","iopub.status.idle":"2021-12-30T22:29:21.347486Z","shell.execute_reply.started":"2021-12-30T22:29:21.341073Z","shell.execute_reply":"2021-12-30T22:29:21.346694Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"BERT understands tokens that were in the training set.\nAll of that work can be done using the encode_plus() method:","metadata":{"id":"kYar71zahZsA"}},{"cell_type":"code","source":"encoding = tokenizer.encode_plus(\n  sample_txt,\n  max_length=32,\n  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n  return_token_type_ids=False,\n  pad_to_max_length=True,\n  return_attention_mask=True,\n  return_tensors='pt',  # Return PyTorch tensors\n)\n\nencoding.keys()","metadata":{"id":"peDV6-3EJn_F","execution":{"iopub.status.busy":"2021-12-30T22:29:23.690891Z","iopub.execute_input":"2021-12-30T22:29:23.693336Z","iopub.status.idle":"2021-12-30T22:29:23.712521Z","shell.execute_reply.started":"2021-12-30T22:29:23.693298Z","shell.execute_reply":"2021-12-30T22:29:23.711566Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(len(encoding['input_ids'][0]))\nencoding['input_ids'][0]","metadata":{"id":"hYNiCu1NJtwX","execution":{"iopub.status.busy":"2021-12-30T22:29:26.166313Z","iopub.execute_input":"2021-12-30T22:29:26.166743Z","iopub.status.idle":"2021-12-30T22:29:26.187059Z","shell.execute_reply.started":"2021-12-30T22:29:26.166703Z","shell.execute_reply":"2021-12-30T22:29:26.186361Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"The attention mask has the same length:\n\n","metadata":{"id":"YuC78u9shsUV"}},{"cell_type":"code","source":"print(len(encoding['attention_mask'][0]))\nencoding['attention_mask']","metadata":{"id":"5N8Ey4oVJwL3","execution":{"iopub.status.busy":"2021-12-30T22:29:32.664914Z","iopub.execute_input":"2021-12-30T22:29:32.665166Z","iopub.status.idle":"2021-12-30T22:29:32.672204Z","shell.execute_reply.started":"2021-12-30T22:29:32.665138Z","shell.execute_reply":"2021-12-30T22:29:32.671472Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n","metadata":{"id":"3Vj18QmOJ2mv","execution":{"iopub.status.busy":"2021-12-30T22:29:35.843229Z","iopub.execute_input":"2021-12-30T22:29:35.843596Z","iopub.status.idle":"2021-12-30T22:29:35.851522Z","shell.execute_reply.started":"2021-12-30T22:29:35.843564Z","shell.execute_reply":"2021-12-30T22:29:35.850686Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"token_lens = []\n\nfor txt in df.title:\n    tokens = tokenizer.encode(txt, max_length=512)\n    token_lens.append(len(tokens))\n","metadata":{"id":"UMsaNrpFA4ks","execution":{"iopub.status.busy":"2021-12-30T22:30:02.130156Z","iopub.execute_input":"2021-12-30T22:30:02.130420Z","iopub.status.idle":"2021-12-30T22:30:11.801292Z","shell.execute_reply.started":"2021-12-30T22:30:02.130390Z","shell.execute_reply":"2021-12-30T22:30:11.800582Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"sns.distplot(token_lens)\nplt.xlim([0, 256]);\nplt.xlabel('Token count');","metadata":{"id":"QyDbiOrABS9L","execution":{"iopub.status.busy":"2021-12-30T22:30:14.131621Z","iopub.execute_input":"2021-12-30T22:30:14.132100Z","iopub.status.idle":"2021-12-30T22:30:14.902130Z","shell.execute_reply.started":"2021-12-30T22:30:14.132065Z","shell.execute_reply":"2021-12-30T22:30:14.901463Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 160\n","metadata":{"id":"d6O7hp8wBYD5","execution":{"iopub.status.busy":"2021-12-30T22:30:19.021565Z","iopub.execute_input":"2021-12-30T22:30:19.022190Z","iopub.status.idle":"2021-12-30T22:30:19.026493Z","shell.execute_reply.started":"2021-12-30T22:30:19.022152Z","shell.execute_reply":"2021-12-30T22:30:19.025430Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"We have all building blocks required to create a PyTorch dataset. Let's do it:\n\n","metadata":{"id":"HSN0JYVnh5m0"}},{"cell_type":"code","source":"class GPReviewDataset(Dataset):\n\n  def __init__(self, reviews, targets, tokenizer, max_len):\n    self.reviews = reviews\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n  \n  def __len__(self):\n    return len(self.reviews)\n  \n  def __getitem__(self, item):\n    review = str(self.reviews[item])\n    target = self.targets[item]\n    \n\n    encoding = self.tokenizer.encode_plus(\n      review,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n\n    return {\n      'review_text': review,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","metadata":{"id":"H613htgwBasn","execution":{"iopub.status.busy":"2021-12-30T22:33:02.117851Z","iopub.execute_input":"2021-12-30T22:33:02.118092Z","iopub.status.idle":"2021-12-30T22:33:02.126955Z","shell.execute_reply.started":"2021-12-30T22:33:02.118065Z","shell.execute_reply":"2021-12-30T22:33:02.126308Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\ndf_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n\n","metadata":{"id":"IV5FtH3CBdEM","execution":{"iopub.status.busy":"2021-12-30T22:33:07.258082Z","iopub.execute_input":"2021-12-30T22:33:07.258349Z","iopub.status.idle":"2021-12-30T22:33:07.272035Z","shell.execute_reply.started":"2021-12-30T22:33:07.258317Z","shell.execute_reply":"2021-12-30T22:33:07.271091Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df_train.shape, df_val.shape, df_test.shape\n","metadata":{"id":"yxGDeUxtBtqz","execution":{"iopub.status.busy":"2021-12-30T22:33:36.112506Z","iopub.execute_input":"2021-12-30T22:33:36.113221Z","iopub.status.idle":"2021-12-30T22:33:36.119996Z","shell.execute_reply.started":"2021-12-30T22:33:36.113176Z","shell.execute_reply":"2021-12-30T22:33:36.119298Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n\n  ds = GPReviewDataset(\n    reviews=df.title.to_numpy(),\n    targets=df.label.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n\n  return DataLoader(ds, batch_size=batch_size, num_workers=4)\n","metadata":{"id":"KV-D6rOFBwnK","execution":{"iopub.status.busy":"2021-12-30T22:33:43.502610Z","iopub.execute_input":"2021-12-30T22:33:43.502884Z","iopub.status.idle":"2021-12-30T22:33:43.508100Z","shell.execute_reply.started":"2021-12-30T22:33:43.502853Z","shell.execute_reply":"2021-12-30T22:33:43.507290Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n","metadata":{"id":"V_BeSYWpCWL-","execution":{"iopub.status.busy":"2021-12-30T22:33:46.157689Z","iopub.execute_input":"2021-12-30T22:33:46.158211Z","iopub.status.idle":"2021-12-30T22:33:46.167874Z","shell.execute_reply.started":"2021-12-30T22:33:46.158174Z","shell.execute_reply":"2021-12-30T22:33:46.166894Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"data = next(iter(train_data_loader))\ndata.keys()","metadata":{"id":"xeN6IM9NC1Wc","execution":{"iopub.status.busy":"2021-12-30T22:33:49.876531Z","iopub.execute_input":"2021-12-30T22:33:49.877067Z","iopub.status.idle":"2021-12-30T22:33:50.076682Z","shell.execute_reply.started":"2021-12-30T22:33:49.877029Z","shell.execute_reply":"2021-12-30T22:33:50.075967Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(data['input_ids'].shape)\nprint(data['attention_mask'].shape)\nprint(data['targets'].shape)","metadata":{"id":"xfe7g82MC7Wf","execution":{"iopub.status.busy":"2021-12-30T22:33:53.344420Z","iopub.execute_input":"2021-12-30T22:33:53.344708Z","iopub.status.idle":"2021-12-30T22:33:53.350673Z","shell.execute_reply.started":"2021-12-30T22:33:53.344665Z","shell.execute_reply":"2021-12-30T22:33:53.349924Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","metadata":{"id":"qp3aigobDEmj","execution":{"iopub.status.busy":"2021-12-30T22:33:56.444094Z","iopub.execute_input":"2021-12-30T22:33:56.444479Z","iopub.status.idle":"2021-12-30T22:34:14.422749Z","shell.execute_reply.started":"2021-12-30T22:33:56.444443Z","shell.execute_reply":"2021-12-30T22:34:14.422024Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"last_hidden_state, pooled_output = bert_model(input_ids=encoding['input_ids'], attention_mask=encoding['attention_mask'])","metadata":{"id":"bCT2wu2IC-JL","execution":{"iopub.status.busy":"2021-12-30T22:34:17.540601Z","iopub.execute_input":"2021-12-30T22:34:17.541160Z","iopub.status.idle":"2021-12-30T22:34:17.753038Z","shell.execute_reply.started":"2021-12-30T22:34:17.541120Z","shell.execute_reply":"2021-12-30T22:34:17.752328Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"bert_model.config.hidden_size\n","metadata":{"id":"xAknMjnCF0bT","execution":{"iopub.status.busy":"2021-12-30T22:34:19.843022Z","iopub.execute_input":"2021-12-30T22:34:19.843784Z","iopub.status.idle":"2021-12-30T22:34:19.850113Z","shell.execute_reply.started":"2021-12-30T22:34:19.843728Z","shell.execute_reply":"2021-12-30T22:34:19.849255Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"Our classifier delegates most of the heavy lifting to the BertModel. We use a dropout layer for some regularization and a fully-connected layer for our output. Note that we're returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work.\n\nThis should work like any other PyTorch model. Let's create an instance and move it to the GPU:","metadata":{"id":"Xn-ZiE6Hj6c1"}},{"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n\n  def __init__(self, n_classes):\n    super(SentimentClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n  \n  def forward(self, input_ids, attention_mask):\n    _, pooled_output = self.bert(\n      input_ids=input_ids,\n      attention_mask=attention_mask,\n       return_dict=False\n    )\n    output = self.drop(pooled_output)\n    return self.out(output)\n","metadata":{"id":"G0lKdTjEKLaL","execution":{"iopub.status.busy":"2021-12-30T22:34:22.991448Z","iopub.execute_input":"2021-12-30T22:34:22.991735Z","iopub.status.idle":"2021-12-30T22:34:22.998764Z","shell.execute_reply.started":"2021-12-30T22:34:22.991705Z","shell.execute_reply":"2021-12-30T22:34:22.997774Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class_names = [\"None\",\"Home & Kitchen\",\"Tools & Home Improvement\",\"Office Products\",\"Grocery & Gourmet Food\" ,\"Industrial & Scientific\" ,\"Electronics\"                   ]\n","metadata":{"id":"fLvDoDbHK1C-","execution":{"iopub.status.busy":"2021-12-30T22:34:25.269017Z","iopub.execute_input":"2021-12-30T22:34:25.269704Z","iopub.status.idle":"2021-12-30T22:34:25.273979Z","shell.execute_reply.started":"2021-12-30T22:34:25.269647Z","shell.execute_reply":"2021-12-30T22:34:25.273311Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"model = SentimentClassifier(len(class_names))\nmodel = model.to(device)","metadata":{"id":"TFOKxj3YKWcO","execution":{"iopub.status.busy":"2021-12-30T22:34:27.096334Z","iopub.execute_input":"2021-12-30T22:34:27.096967Z","iopub.status.idle":"2021-12-30T22:34:33.311008Z","shell.execute_reply.started":"2021-12-30T22:34:27.096926Z","shell.execute_reply":"2021-12-30T22:34:33.310143Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"input_ids = data['input_ids'].to(device)\nattention_mask = data['attention_mask'].to(device)\n\nprint(input_ids.shape) # batch size x seq length\nprint(attention_mask.shape) # batch size x seq lengt","metadata":{"id":"Yb3t3pCwKiiF","execution":{"iopub.status.busy":"2021-12-30T22:34:37.351933Z","iopub.execute_input":"2021-12-30T22:34:37.352190Z","iopub.status.idle":"2021-12-30T22:34:37.358525Z","shell.execute_reply.started":"2021-12-30T22:34:37.352162Z","shell.execute_reply":"2021-12-30T22:34:37.357695Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"F.softmax(model(input_ids, attention_mask), dim=1)\n","metadata":{"id":"u0QBLIAwLyrU","execution":{"iopub.status.busy":"2021-12-30T22:36:08.023196Z","iopub.execute_input":"2021-12-30T22:36:08.023458Z","iopub.status.idle":"2021-12-30T22:36:08.894227Z","shell.execute_reply.started":"2021-12-30T22:36:08.023429Z","shell.execute_reply":"2021-12-30T22:36:08.893526Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Now we have to adjust the weight ","metadata":{"id":"g_nffJZfiE_E"}},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\nclass_weights = compute_class_weight(\n                                        class_weight = \"balanced\",\n                                        classes = np.unique(df_train['label']),\n                                        y = df_train['label']                                                    \n                                    )\n","metadata":{"id":"wiulh16GWXE-","execution":{"iopub.status.busy":"2021-12-30T22:36:11.595358Z","iopub.execute_input":"2021-12-30T22:36:11.596216Z","iopub.status.idle":"2021-12-30T22:36:11.607142Z","shell.execute_reply.started":"2021-12-30T22:36:11.596165Z","shell.execute_reply":"2021-12-30T22:36:11.606556Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"print(class_weights)\n","metadata":{"id":"WpeNU_VrXj5Y","execution":{"iopub.status.busy":"2021-12-30T22:36:13.647403Z","iopub.execute_input":"2021-12-30T22:36:13.649012Z","iopub.status.idle":"2021-12-30T22:36:13.655899Z","shell.execute_reply.started":"2021-12-30T22:36:13.648976Z","shell.execute_reply":"2021-12-30T22:36:13.653889Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"weights= torch.tensor(class_weights,dtype=torch.float)\nweights = weights.to(device)","metadata":{"id":"CKDaPRplXzV0","execution":{"iopub.status.busy":"2021-12-30T22:36:15.988459Z","iopub.execute_input":"2021-12-30T22:36:15.989178Z","iopub.status.idle":"2021-12-30T22:36:15.995695Z","shell.execute_reply.started":"2021-12-30T22:36:15.989139Z","shell.execute_reply":"2021-12-30T22:36:15.994966Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"Training:- \nTo reproduce the training procedure from the BERT paper, we'll use the AdamW optimizer provided by Hugging Face. It corrects weight decay, so it's similar to the original paper. We'll also use a linear scheduler with no warmup steps:","metadata":{"id":"u2q9QKHCkNJv"}},{"cell_type":"code","source":"EPOCHS = 10\n\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\n\n\nloss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n","metadata":{"id":"q7CPevIRL3PP","execution":{"iopub.status.busy":"2021-12-30T22:36:18.948036Z","iopub.execute_input":"2021-12-30T22:36:18.948286Z","iopub.status.idle":"2021-12-30T22:36:18.960269Z","shell.execute_reply.started":"2021-12-30T22:36:18.948254Z","shell.execute_reply":"2021-12-30T22:36:18.959351Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"\n\nBatch size: 16, 32\nLearning rate (Adam): 5e-5, 3e-5, 2e-5\nNumber of epochs: 2, 3, 4\n","metadata":{"id":"-b8JzwwNkfd0"}},{"cell_type":"code","source":"def train_epoch(\n  model, \n  data_loader, \n  loss_fn, \n  optimizer, \n  device, \n  scheduler, \n  n_examples\n):\n  model = model.train()\n\n  losses = []\n  correct_predictions = 0\n  \n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"0QaQwluhM22z","execution":{"iopub.status.busy":"2021-12-30T22:36:21.846094Z","iopub.execute_input":"2021-12-30T22:36:21.846344Z","iopub.status.idle":"2021-12-30T22:36:21.854710Z","shell.execute_reply.started":"2021-12-30T22:36:21.846316Z","shell.execute_reply":"2021-12-30T22:36:21.853887Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n\n  losses = []\n  correct_predictions = 0\n\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n\n      loss = loss_fn(outputs, targets)\n\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"1TA_HIiQM9Gn","execution":{"iopub.status.busy":"2021-12-30T22:36:29.073948Z","iopub.execute_input":"2021-12-30T22:36:29.074193Z","iopub.status.idle":"2021-12-30T22:36:29.081193Z","shell.execute_reply.started":"2021-12-30T22:36:29.074165Z","shell.execute_reply":"2021-12-30T22:36:29.080146Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"%%time\n\nhistory = defaultdict(list)\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\n  print('-' * 10)\n\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,    \n    loss_fn, \n    optimizer, \n    device, \n    scheduler, \n    len(df_train)\n  )\n\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn, \n    device, \n    len(df_val)\n  )\n\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n\n  if val_acc > best_accuracy:\n    torch.save(model.state_dict(), 'best_model_state.bin')\n    best_accuracy = val_acc","metadata":{"id":"L6nwUsXcNAKR","execution":{"iopub.status.busy":"2021-12-30T22:43:37.477609Z","iopub.execute_input":"2021-12-30T22:43:37.478201Z","iopub.status.idle":"2021-12-30T23:38:37.362231Z","shell.execute_reply.started":"2021-12-30T22:43:37.478163Z","shell.execute_reply":"2021-12-30T23:38:37.361399Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"plt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\n\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.ylim([0, 1]);","metadata":{"id":"3quM91McNECC","execution":{"iopub.status.busy":"2021-12-30T23:43:56.865249Z","iopub.execute_input":"2021-12-30T23:43:56.865515Z","iopub.status.idle":"2021-12-30T23:43:57.263104Z","shell.execute_reply.started":"2021-12-30T23:43:56.865482Z","shell.execute_reply":"2021-12-30T23:43:57.262449Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"id":"VZabu6kGsaJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/pertainedmodel/best_model_state.bin'\nmodel.load_state_dict(torch.load(path))","metadata":{"id":"iJBJ-bhqsXF4","execution":{"iopub.status.busy":"2021-12-30T22:36:52.815724Z","iopub.execute_input":"2021-12-30T22:36:52.816226Z","iopub.status.idle":"2021-12-30T22:36:57.654006Z","shell.execute_reply.started":"2021-12-30T22:36:52.816189Z","shell.execute_reply":"2021-12-30T22:36:57.653290Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"test_acc, _ = eval_model(\n  model,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\n\ntest_acc.item()","metadata":{"id":"rILveL-JAsYf","execution":{"iopub.status.busy":"2021-12-30T23:44:12.605152Z","iopub.execute_input":"2021-12-30T23:44:12.605411Z","iopub.status.idle":"2021-12-30T23:44:18.899400Z","shell.execute_reply.started":"2021-12-30T23:44:12.605381Z","shell.execute_reply":"2021-12-30T23:44:18.898689Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"w9KKFVqdsrfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model, data_loader):\n  model = model.eval()\n  \n  review_texts = []\n  predictions = []\n  prediction_probs = []\n  real_values = []\n\n  with torch.no_grad():\n    for d in data_loader:\n\n      texts = d[\"review_text\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n\n      probs = F.softmax(outputs, dim=1)\n\n      review_texts.extend(texts)\n      predictions.extend(preds)\n      prediction_probs.extend(probs)\n      real_values.extend(targets)\n\n  predictions = torch.stack(predictions).cpu()\n  prediction_probs = torch.stack(prediction_probs).cpu()\n  real_values = torch.stack(real_values).cpu()\n  return review_texts, predictions, prediction_probs, real_values","metadata":{"id":"wE3TkFw0AyEa","execution":{"iopub.status.busy":"2021-12-30T22:37:08.692071Z","iopub.execute_input":"2021-12-30T22:37:08.692491Z","iopub.status.idle":"2021-12-30T22:37:08.704118Z","shell.execute_reply.started":"2021-12-30T22:37:08.692452Z","shell.execute_reply":"2021-12-30T22:37:08.703260Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n  model,\n  test_data_loader\n)","metadata":{"id":"SxPKkejsA67P","execution":{"iopub.status.busy":"2021-12-30T22:37:12.772339Z","iopub.execute_input":"2021-12-30T22:37:12.772586Z","iopub.status.idle":"2021-12-30T22:37:18.895216Z","shell.execute_reply.started":"2021-12-30T22:37:12.772558Z","shell.execute_reply":"2021-12-30T22:37:18.894308Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, target_names=class_names))\n","metadata":{"id":"xvTZft_yBBkE","execution":{"iopub.status.busy":"2021-12-30T22:37:18.898487Z","iopub.execute_input":"2021-12-30T22:37:18.898714Z","iopub.status.idle":"2021-12-30T22:37:18.912970Z","shell.execute_reply.started":"2021-12-30T22:37:18.898687Z","shell.execute_reply":"2021-12-30T22:37:18.912295Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def show_confusion_matrix(confusion_matrix):\n  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n  plt.ylabel('True sentiment')\n  plt.xlabel('Predicted sentiment');\n\ncm = confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\nshow_confusion_matrix(df_cm)\n","metadata":{"id":"57IlCHrHBLsV","execution":{"iopub.status.busy":"2021-12-30T22:37:26.706494Z","iopub.execute_input":"2021-12-30T22:37:26.707017Z","iopub.status.idle":"2021-12-30T22:37:27.424989Z","shell.execute_reply.started":"2021-12-30T22:37:26.706979Z","shell.execute_reply":"2021-12-30T22:37:27.424232Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"test = 'John Deere 0071750GX22269 Genuine Original Equipment Manufacturer (OEM) Part'","metadata":{"execution":{"iopub.status.busy":"2021-12-30T22:39:06.660309Z","iopub.execute_input":"2021-12-30T22:39:06.660556Z","iopub.status.idle":"2021-12-30T22:39:06.664355Z","shell.execute_reply.started":"2021-12-30T22:39:06.660528Z","shell.execute_reply":"2021-12-30T22:39:06.663674Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"encoded_review = tokenizer.encode_plus(\n    test,\n    max_length=MAX_LEN,\n    add_special_tokens=True,\n    return_token_type_ids=False,\n    pad_to_max_length=True,\n    return_attention_mask=True,\n    return_tensors='pt',)","metadata":{"id":"5DTYuxkqBsDj","execution":{"iopub.status.busy":"2021-12-30T22:39:11.993068Z","iopub.execute_input":"2021-12-30T22:39:11.993750Z","iopub.status.idle":"2021-12-30T22:39:12.000964Z","shell.execute_reply.started":"2021-12-30T22:39:11.993710Z","shell.execute_reply":"2021-12-30T22:39:11.999393Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"input_ids = encoded_review['input_ids'].to(device)\nattention_mask = encoded_review['attention_mask'].to(device)\n\noutput = model(input_ids, attention_mask)\n_, prediction = torch.max(output, dim=1)\n\nprint(f'Review text: {test}')\nprint(f'Sentiment  : {class_names[prediction]}')","metadata":{"execution":{"iopub.status.busy":"2021-12-30T22:40:06.147409Z","iopub.execute_input":"2021-12-30T22:40:06.147968Z","iopub.status.idle":"2021-12-30T22:40:06.176011Z","shell.execute_reply.started":"2021-12-30T22:40:06.147929Z","shell.execute_reply":"2021-12-30T22:40:06.175326Z"},"trusted":true},"execution_count":77,"outputs":[]}]}